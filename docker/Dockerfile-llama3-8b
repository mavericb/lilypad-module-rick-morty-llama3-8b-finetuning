# Use NVIDIA CUDA base image
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04 AS builder

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update -y && \
    apt-get install -y curl python3 python3-pip git libgl1-mesa-glx libglib2.0-0 && \
    rm -rf /var/lib/apt/lists/*

# Copy and install Python dependencies
COPY requirements.txt /app/requirements.txt
RUN pip3 install --no-cache-dir -r requirements.txt

# Download model and dataset
RUN python3 -c "from transformers import AutoTokenizer, AutoModelForCausalLM; AutoTokenizer.from_pretrained('NousResearch/Meta-Llama-3-8B-Instruct'); AutoModelForCausalLM.from_pretrained('NousResearch/Meta-Llama-3-8B-Instruct')"
RUN python3 -c "from datasets import load_dataset; load_dataset('jmaczan/rick-and-morty-scripts-llama-2', split='train')"

# Copy application files
COPY Dockerfile-llama3-8b /app/Dockerfile-llama3-8b
COPY main.py /app/main.py
COPY requirements.txt /app/requirements.txt
COPY start.sh /app/start.sh

# Make start.sh executable
RUN chmod +x /app/start.sh

# Set environment variables for runtime
ENV TRANSFORMERS_OFFLINE=1
ENV HF_DATASETS_OFFLINE=1

# Set the entrypoint
ENTRYPOINT ["/app/start.sh"]
